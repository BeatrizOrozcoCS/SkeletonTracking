{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e09c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "import operator as op\n",
    "import math\n",
    "from hmmlearn import hmm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a7302ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscount = 50\n",
    "nstates = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e7da7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = [\"DateTime\",\n",
    "\"HipCenter X\",\"HipCenter Y\",\"HipCenter Z\",\"HipCenter Depth\",\n",
    "\"Spine X\",\"Spine Y\",\"Spine Z\",\"Spine Depth\",\n",
    "\"Head X\",\"Head Y\",\"Head Z\",\"Head Depth\",\n",
    "\"ShoulderCenter X\",\"ShoulderCenter Y\",\"ShoulderCenter Z\",\"ShoulderCenter Depth\",\n",
    "\"ShoulderLeft X\",\"ShoulderLeft Y\",\"ShoulderLeft Z\",\"ShoulderLeft Depth\",\n",
    "\"ElbowLeft X\",\"ElbowLeft Y\",\"ElbowLeft Z\",\"ElbowLeft Depth\",\n",
    "\"WristLeft X\",\"WristLeft Y\",\"WristLeft Z\",\"WristLeft Depth\",\n",
    "\"HandLeft X\",\"HandLeft Y\",\"HandLeft Z\",\"HandLeft Depth\",\n",
    "\"ShoulderRight X\",\"ShoulderRight Y\",\"ShoulderRight Z\",\"ShoulderRight Depth\",\n",
    "\"ElbowRight X\",\"ElbowRight Y\",\"ElbowRight Z\",\"ElbowRight Depth\",\n",
    "\"WristRight X\",\"WristRight Y\",\"WristRight Z\",\"WristRight Depth\",\n",
    "\"HandRight X\",\"HandRight Y\",\"HandRight Z\",\"HandRight Depth\",\n",
    "\"HipLeft X\",\"HipLeft Y\",\"HipLeft Z\",\"HipLeft Depth\",\n",
    "\"KneeLeft X\",\"KneeLeft Y\",\"KneeLeft Z\",\"KneeLeft Depth\",\n",
    "\"AnkleLeft X\",\"AnkleLeft Y\",\"AnkleLeft Z\",\"AnkleLeft Depth\",\n",
    "\"FootLeft X\",\"FootLeft Y\",\"FootLeft Z\",\"FootLeft Depth\",\n",
    "\"HipRight X\",\"HipRight Y\",\"HipRight Z\",\"HipRight Depth\",\n",
    "\"KneeRight X\",\"KneeRight Y\",\"KneeRight Z\",\"KneeRight Depth\",\n",
    "\"AnkleRight X\",\"AnkleRight Y\",\"AnkleRight Z\",\"AnkleRight Depth\",\n",
    "\"FootRight X\",\"FootRight Y\",\"FootRight Z\",\"FootRight Depth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c50cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Sets\n",
    "classfication = [\"not moving\", \"moving\"]\n",
    "\n",
    "fileWalkingSet = r\"C:\\Users\\Orozc\\OneDrive\\My Documents\\CPP\\ME 6950\\Test Set\\Walking\"\n",
    "fileNotWalking = r\"C:\\Users\\Orozc\\OneDrive\\My Documents\\CPP\\ME 6950\\Test Set\\Not Walking\"\n",
    "\n",
    "#data sets\n",
    "##walking\n",
    "walking1 = pd.read_csv(fileWalkingSet + \"\\\\Waling 1.txt\", names = columnNames)\n",
    "walking2 = pd.read_csv(fileWalkingSet + \"\\\\Waling 2.txt\", names = columnNames)\n",
    "walking3 = pd.read_csv(fileWalkingSet + \"\\\\Waling 3.txt\", names = columnNames)\n",
    "walking4 = pd.read_csv(fileWalkingSet + \"\\\\Waling 4.txt\", names = columnNames)\n",
    "walking5 = pd.read_csv(fileWalkingSet + \"\\\\Waling 6.txt\", names = columnNames)\n",
    "walking6 = pd.read_csv(fileWalkingSet + \"\\\\Waling7.txt\", names = columnNames)\n",
    "walking7 = pd.read_csv(fileWalkingSet + \"\\\\Waling8.txt\", names = columnNames)\n",
    "walking8 = pd.read_csv(fileWalkingSet + \"\\\\Waling9.txt\", names = columnNames)\n",
    "walking9 = pd.read_csv(fileWalkingSet + \"\\\\Waling10.txt\", names = columnNames)\n",
    "walking10 = pd.read_csv(fileWalkingSet + \"\\\\Waling11.txt\", names = columnNames)\n",
    "\n",
    "\n",
    "##notwalking\n",
    "notwalking1 = pd.read_csv(fileNotWalking + \"\\\\Standing1.txt\", names = columnNames)\n",
    "notwalking2 = pd.read_csv(fileNotWalking + \"\\\\Standing2.txt\", names = columnNames)\n",
    "notwalking3 = pd.read_csv(fileNotWalking + \"\\\\Standing3.txt\", names = columnNames)\n",
    "notwalking4 = pd.read_csv(fileNotWalking + \"\\\\Standing4.txt\", names = columnNames)\n",
    "notwalking5 = pd.read_csv(fileNotWalking + \"\\\\Standing5.txt\", names = columnNames)\n",
    "notwalking6 = pd.read_csv(fileNotWalking + \"\\\\Standing6.txt\", names = columnNames)\n",
    "notwalking7 = pd.read_csv(fileNotWalking + \"\\\\Standing7.txt\", names = columnNames)\n",
    "\n",
    "\n",
    "#dropping depth columns\n",
    "##walking\n",
    "walking1 = walking1.loc[:,~walking1.columns.str.endswith('Depth')]\n",
    "walking2 = walking2.loc[:,~walking2.columns.str.endswith('Depth')]\n",
    "walking3 = walking3.loc[:,~walking3.columns.str.endswith('Depth')]\n",
    "walking4 = walking4.loc[:,~walking4.columns.str.endswith('Depth')]\n",
    "walking5 = walking5.loc[:,~walking5.columns.str.endswith('Depth')]\n",
    "walking6 = walking6.loc[:,~walking6.columns.str.endswith('Depth')]\n",
    "walking7 = walking7.loc[:,~walking7.columns.str.endswith('Depth')]\n",
    "walking8 = walking8.loc[:,~walking8.columns.str.endswith('Depth')]\n",
    "walking9 = walking9.loc[:,~walking9.columns.str.endswith('Depth')]\n",
    "walking10 = walking10.loc[:,~walking10.columns.str.endswith('Depth')]\n",
    "\n",
    "\n",
    "##notwalking\n",
    "notwalking1 = notwalking1.loc[:,~notwalking1.columns.str.endswith('Depth')]\n",
    "notwalking2 = notwalking2.loc[:,~notwalking2.columns.str.endswith('Depth')]\n",
    "notwalking3 = notwalking3.loc[:,~notwalking3.columns.str.endswith('Depth')]\n",
    "notwalking4 = notwalking4.loc[:,~notwalking4.columns.str.endswith('Depth')]\n",
    "notwalking5 = notwalking5.loc[:,~notwalking5.columns.str.endswith('Depth')]\n",
    "notwalking6 = notwalking6.loc[:,~notwalking6.columns.str.endswith('Depth')]\n",
    "notwalking7 = notwalking7.loc[:,~notwalking7.columns.str.endswith('Depth')]\n",
    "\n",
    "\n",
    "#dropping Foot\n",
    "\n",
    "\n",
    "#fixing the columnNames\n",
    "for element in columnNames:\n",
    "    if \"Depth\" in element:\n",
    "        columnNames.remove(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4c7b7",
   "metadata": {},
   "source": [
    "#  Walking HMM model (walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d9928de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "#data /Date Time was messing with results, drop rows with na values in any columns\n",
    "x = [walking1.drop(columns=[\"DateTime\"]).dropna(),walking2.drop(columns=[\"DateTime\"]).dropna(),\n",
    "     walking3.drop(columns=[\"DateTime\"]).dropna(),\n",
    "     walking4.drop(columns=[\"DateTime\"]).dropna(), walking5.drop(columns=[\"DateTime\"]).dropna(),\n",
    "     walking6.drop(columns=[\"DateTime\"]).dropna(),\n",
    "    walking7.drop(columns=[\"DateTime\"]).dropna()]\n",
    "\n",
    "X_walking=[]\n",
    "y=[]\n",
    "\n",
    "number =[]\n",
    "#break up the data and create an array of differences (get the average difference of 5 frames (5 rows))\n",
    "for i in range(0,len(x)):\n",
    "    a=0\n",
    "    frames = 5 #getting the abs average of the frames\n",
    "    #get the closest divisble number of a selected frame\n",
    "    lengths = len(x[i]) - len(x[i])%frames#frames \n",
    "    for j in range(0,lengths-frames,frames): #change in pixel location\n",
    "        a1 = abs(x[i].iloc[j]-x[i].iloc[j+1])\n",
    "        a2 = abs(x[i].iloc[j+1]-x[i].iloc[j+2])\n",
    "        a3 = abs(x[i].iloc[j+2]-x[i].iloc[j+3])\n",
    "        a4 = abs(x[i].iloc[j+3]-x[i].iloc[j+4])\n",
    "        a5 = abs(x[i].iloc[j+4]-x[i].iloc[j+5])\n",
    "        #transpose the series, combine the series into one dataframe and grab the max values'\n",
    "        a = (pd.concat([a1.to_frame().T,a2.to_frame().T,a3.to_frame().T,a4.to_frame().T,a5.to_frame().T])).max()\n",
    "        a.reset_index(drop=True, inplace=True)\n",
    "        X_walking.append(a) #max difference between five frames\n",
    "        \n",
    "        #number.append(i)\n",
    "        number.append(len(a1))\n",
    "        b = a\n",
    "        a = 0\n",
    "        if i<6:\n",
    "           # y.append(classfication[1]) #1 - walking\n",
    "            y.append([1])\n",
    "        else:\n",
    "           # y.append(classfication[0]) #2 - not walking\n",
    "            y.append([0])\n",
    "            \n",
    "walkingModels =[]\n",
    "walking_hidden_states = []\n",
    "for i in range(0,modelscount):\n",
    "    # Define the CategoricalHMM model\n",
    "    walkingModel = hmm.GaussianHMM(n_components=nstates, n_iter=1).fit(X_walking)\n",
    "    # Predict the hidden states\n",
    "    walking_hidden_states =(walkingModel.predict(X_walking))\n",
    "    walkingModels.append(walkingModel)\n",
    "#prob = walkingModel.score(X_walking)\n",
    "#prob_next_step = walkingModel.transmat_[hidden_states[99], :]\n",
    "#prob_next_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74dabc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 0, 0, 0, 3, 1, 2, 0, 0, 2, 3, 3, 4, 0, 2, 2, 0, 0, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 0, 2, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2,\n",
       "       0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walkingModel.predict(X_walking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8f07e",
   "metadata": {},
   "source": [
    "# HMM (not walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92a43b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "#data /Date Time was messing with results, drop rows with na values in any columns\n",
    "x = [notwalking1.drop(columns=[\"DateTime\"]).dropna(), notwalking2.drop(columns=[\"DateTime\"]).dropna(), \n",
    "     notwalking3.drop(columns=[\"DateTime\"]).dropna(),\n",
    "     notwalking4.drop(columns=[\"DateTime\"]).dropna(),notwalking5.drop(columns=[\"DateTime\"]).dropna(),\n",
    "     notwalking6.drop(columns=[\"DateTime\"]).dropna(),notwalking7.drop(columns=[\"DateTime\"]).dropna()]\n",
    "\n",
    "X_notwalking=[]\n",
    "y=[]\n",
    "\n",
    "number =[]\n",
    "#break up the data and create an array of differences (get the average difference of 5 frames (5 rows))\n",
    "for i in range(0,len(x)):\n",
    "    a=0\n",
    "    frames = 5 #getting the abs average of the frames\n",
    "    #get the closest divisble number of a selected frame\n",
    "    lengths = len(x[i]) - len(x[i])%frames#frames \n",
    "    for j in range(0,lengths-frames,frames): #change in pixel location\n",
    "        a1 = abs(x[i].iloc[j]-x[i].iloc[j+1])\n",
    "        a2 = abs(x[i].iloc[j+1]-x[i].iloc[j+2])\n",
    "        a3 = abs(x[i].iloc[j+2]-x[i].iloc[j+3])\n",
    "        a4 = abs(x[i].iloc[j+3]-x[i].iloc[j+4])\n",
    "        a5 = abs(x[i].iloc[j+4]-x[i].iloc[j+5])\n",
    "        #transpose the series, combine the series into one dataframe and grab the max values'\n",
    "        a = (pd.concat([a1.to_frame().T,a2.to_frame().T,a3.to_frame().T,a4.to_frame().T,a5.to_frame().T])).max() \n",
    "        a.reset_index(drop=True, inplace=True)\n",
    "        X_notwalking.append(a) #max difference between five frames\n",
    "\n",
    "        if i<6:\n",
    "           # y.append(classfication[1]) #1 - walking\n",
    "            y.append([1])\n",
    "        else:\n",
    "           # y.append(classfication[0]) #2 - not walking\n",
    "            y.append([0])\n",
    "            \n",
    "notwalkingModels = []\n",
    "notwalking_hidden_states = []\n",
    "for i in range(0,modelscount):\n",
    "    # Define the CategoricalHMM model\n",
    "    notwalkingModel = hmm.GaussianHMM(n_components=nstates, n_iter=1).fit(X_notwalking)\n",
    "    # Predict the hidden states\n",
    "    notwalking_hidden_states=notwalkingModel.predict(X_notwalking)\n",
    "    notwalkingModels.append(notwalkingModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc082238",
   "metadata": {},
   "source": [
    "# Open Trial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3935a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with other data sets\n",
    "\n",
    "columnNames = [\"DateTime\",\n",
    "\"HipCenter X\",\"HipCenter Y\",\"HipCenter Z\",\"HipCenter Depth\",\n",
    "\"Spine X\",\"Spine Y\",\"Spine Z\",\"Spine Depth\",\n",
    "\"Head X\",\"Head Y\",\"Head Z\",\"Head Depth\",\n",
    "\"ShoulderCenter X\",\"ShoulderCenter Y\",\"ShoulderCenter Z\",\"ShoulderCenter Depth\",\n",
    "\"ShoulderLeft X\",\"ShoulderLeft Y\",\"ShoulderLeft Z\",\"ShoulderLeft Depth\",\n",
    "\"ElbowLeft X\",\"ElbowLeft Y\",\"ElbowLeft Z\",\"ElbowLeft Depth\",\n",
    "\"WristLeft X\",\"WristLeft Y\",\"WristLeft Z\",\"WristLeft Depth\",\n",
    "\"HandLeft X\",\"HandLeft Y\",\"HandLeft Z\",\"HandLeft Depth\",\n",
    "\"ShoulderRight X\",\"ShoulderRight Y\",\"ShoulderRight Z\",\"ShoulderRight Depth\",\n",
    "\"ElbowRight X\",\"ElbowRight Y\",\"ElbowRight Z\",\"ElbowRight Depth\",\n",
    "\"WristRight X\",\"WristRight Y\",\"WristRight Z\",\"WristRight Depth\",\n",
    "\"HandRight X\",\"HandRight Y\",\"HandRight Z\",\"HandRight Depth\",\n",
    "\"HipLeft X\",\"HipLeft Y\",\"HipLeft Z\",\"HipLeft Depth\",\n",
    "\"KneeLeft X\",\"KneeLeft Y\",\"KneeLeft Z\",\"KneeLeft Depth\",\n",
    "\"AnkleLeft X\",\"AnkleLeft Y\",\"AnkleLeft Z\",\"AnkleLeft Depth\",\n",
    "\"FootLeft X\",\"FootLeft Y\",\"FootLeft Z\",\"FootLeft Depth\",\n",
    "\"HipRight X\",\"HipRight Y\",\"HipRight Z\",\"HipRight Depth\",\n",
    "\"KneeRight X\",\"KneeRight Y\",\"KneeRight Z\",\"KneeRight Depth\",\n",
    "\"AnkleRight X\",\"AnkleRight Y\",\"AnkleRight Z\",\"AnkleRight Depth\",\n",
    "\"FootRight X\",\"FootRight Y\",\"FootRight Z\",\"FootRight Depth\"]\n",
    "\n",
    "## Not blind\n",
    "PredictionFileLocation = r\"C:\\Users\\Orozc\\OneDrive\\My Documents\\CPP\\ME 6950\\SVM Models\\prediction\\not blind\"\n",
    "#Data Sets\n",
    "test1 = pd.read_csv(PredictionFileLocation + \"\\\\notwalking_Pred1.txt\", names = columnNames)\n",
    "test2 = pd.read_csv(PredictionFileLocation + \"\\\\notwalking_Pred2.txt\", names = columnNames)\n",
    "test3 = pd.read_csv(PredictionFileLocation + \"\\\\notwalking_Pred3.txt\", names = columnNames)\n",
    "test4 = pd.read_csv(PredictionFileLocation + \"\\\\notwalking_Pred4.txt\", names = columnNames)\n",
    "test5 = pd.read_csv(PredictionFileLocation + \"\\\\notwalking_Pred5.txt\", names = columnNames)\n",
    "\n",
    "test6 = pd.read_csv(PredictionFileLocation + \"\\\\walking_Pred1.txt\", names = columnNames)\n",
    "test7 = pd.read_csv(PredictionFileLocation + \"\\\\walking_Pred2.txt\", names = columnNames)\n",
    "test8 = pd.read_csv(PredictionFileLocation + \"\\\\walking_Pred3.txt\", names = columnNames)\n",
    "test9 = pd.read_csv(PredictionFileLocation + \"\\\\walking_Pred4.txt\", names = columnNames)\n",
    "test10 = pd.read_csv(PredictionFileLocation + \"\\\\walking_Pred5.txt\", names = columnNames)\n",
    "\n",
    "\n",
    "#dropping depth columns\n",
    "##not walking\n",
    "test1 = test1.loc[:,~test1.columns.str.endswith('Depth')]\n",
    "test2 = test2.loc[:,~test2.columns.str.endswith('Depth')]\n",
    "test3 = test3.loc[:,~test3.columns.str.endswith('Depth')]\n",
    "test4 = test4.loc[:,~test4.columns.str.endswith('Depth')]\n",
    "test5 = test5.loc[:,~test5.columns.str.endswith('Depth')]\n",
    "\n",
    "##walking\n",
    "test6 = test6.loc[:,~test6.columns.str.endswith('Depth')]\n",
    "test7 = test7.loc[:,~test7.columns.str.endswith('Depth')]\n",
    "test8 = test8.loc[:,~test8.columns.str.endswith('Depth')]\n",
    "test9 = test9.loc[:,~test9.columns.str.endswith('Depth')]\n",
    "test10 = test10.loc[:,~test10.columns.str.endswith('Depth')]\n",
    "\n",
    "\n",
    "\n",
    "#dropping depth columns\n",
    "##walking\n",
    "test1 = test1.loc[:,~test1.columns.str.endswith('Depth')]\n",
    "test2 = test2.loc[:,~test2.columns.str.endswith('Depth')]\n",
    "test3 = test3.loc[:,~test3.columns.str.endswith('Depth')]\n",
    "test4 = test4.loc[:,~test4.columns.str.endswith('Depth')]\n",
    "test5 = test5.loc[:,~test5.columns.str.endswith('Depth')]\n",
    "test6 = test6.loc[:,~test6.columns.str.endswith('Depth')]\n",
    "test7 = test7.loc[:,~test7.columns.str.endswith('Depth')]\n",
    "test8 = test8.loc[:,~test8.columns.str.endswith('Depth')]\n",
    "test9 = test9.loc[:,~test9.columns.str.endswith('Depth')]\n",
    "test10 = test10.loc[:,~test10.columns.str.endswith('Depth')]\n",
    "\n",
    "#fixing the columnNames\n",
    "for element in columnNames:\n",
    "    if \"Depth\" in element:\n",
    "        columnNames.remove(element)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1ce7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed the data\n",
    "x_pred = [test1.drop(columns=[\"DateTime\"]).dropna(),test2.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test3.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test4.drop(columns=[\"DateTime\"]).dropna(),test5.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test6.drop(columns=[\"DateTime\"]).dropna(),test7.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test8.drop(columns=[\"DateTime\"]).dropna(),test9.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test10.drop(columns=[\"DateTime\"]).dropna()]\n",
    "X_pred = []\n",
    "y_pred = []\n",
    "for i in range(0,len(x_pred)):\n",
    "    a=0\n",
    "    frames = 5 #getting the abs average of the frames\n",
    "    #get the closest divisble number of a selected frame\n",
    "    lengths = len(x_pred[i]) - len(x_pred[i])%frames#frames \n",
    "    for j in range(0,lengths-frames,frames): #change in pixel location\n",
    "        a=0\n",
    "\n",
    "        a1 = abs(x_pred[i].iloc[j]-x_pred[i].iloc[j+1])\n",
    "        a2 = abs(x_pred[i].iloc[j+1]-x_pred[i].iloc[j+2])\n",
    "        a3 = abs(x_pred[i].iloc[j+2]-x_pred[i].iloc[j+3])\n",
    "        a4 = abs(x_pred[i].iloc[j+3]-x_pred[i].iloc[j+4])\n",
    "        a5 = abs(x_pred[i].iloc[j+4]-x_pred[i].iloc[j+5])\n",
    "        a = (pd.concat([a1.to_frame().T,a2.to_frame().T,a3.to_frame().T,a4.to_frame().T,a5.to_frame().T])).max()\n",
    "        \n",
    "        X_pred.append(a) #average difference of the five frames\n",
    "       \n",
    "        if i>4:\n",
    "            y_pred.append(classfication[1]) #1 - walking\n",
    "        else:\n",
    "            y_pred.append(classfication[0]) #2 - not walkin\n",
    "            \n",
    "# Predict the hidden states\n",
    "#notwalking_hidden_states = notwalkingModel.predict(X_pred)\n",
    "#notwalking_prob = notwalkingModel.score(X_pred)\n",
    "\n",
    "# Predict the hidden states\n",
    "#walking_hidden_states = walkingModel.predict(X_pred)\n",
    "#walking_prob = walkingModel.score(X_pred)\n",
    "\n",
    "\n",
    "\n",
    "notwalking_prob_next_step_list = []\n",
    "walking_prob_next_step_list = []\n",
    "for j in range(0, modelscount):\n",
    "    #print(i)\n",
    "    walking_prob_next_step = walkingModels[j].transmat_[walkingModels[j].predict(X_pred), walkingModels[j].predict(X_pred)]\n",
    "    notwalking_prob_next_step = notwalkingModels[j].transmat_[notwalkingModels[j].predict(X_pred), notwalkingModels[j].predict(X_pred)]\n",
    "    walking_prob_next_step_list.append(walking_prob_next_step)\n",
    "    notwalking_prob_next_step_list.append(notwalking_prob_next_step)\n",
    "#print(max(walkingprob_list),max(notwalkingprob_list))\n",
    "\n",
    "\n",
    "HMM_predictions = []\n",
    "walkingprob_list = []\n",
    "notwalkingprob_list = []\n",
    "walking_step_probablity = []\n",
    "notwalking_step_probablity = []    \n",
    "for i in range(0, len(X_pred)):\n",
    "    a=[]\n",
    "    b=[]\n",
    "    for j in range(0, modelscount):\n",
    "        a.append(notwalking_prob_next_step_list[j][i])\n",
    "        b.append(walking_prob_next_step_list[j][i])\n",
    "    notwalking_step_probablity.append(max(a))\n",
    "    walking_step_probablity.append(max(b))\n",
    "    notwalkingprob=(max(a))\n",
    "    walkingprob=(max(b))\n",
    "    #print(notwalkingprob,walkingprob)\n",
    "    if walkingprob > notwalkingprob:\n",
    "        HMM_predictions.append(classfication[1])#1 - walking\n",
    "    else:\n",
    "        HMM_predictions.append(classfication[0])#0 - ot walking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fcb7067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking Count 367\n",
      "Not Walking Count 910\n",
      "HMM Walking Count (Predict) 931\n",
      "HMM Not Walking Count (Predict) 346\n",
      "HMM Walking Count (Correct) 359\n",
      "HMM Not Walking Count (Correct) 338\n",
      "Accuraccy:  54.581049334377454\n"
     ]
    }
   ],
   "source": [
    "# compare HMM predictions vs actual labels\n",
    "correct_walking = 0 #correct \n",
    "correct_notwalking = 0 #correct\n",
    "walking_num = 0 #track of overall count\n",
    "notwalking_num = 0  #tack overall count\n",
    "predicted_walking = 0\n",
    "predicted_notwalking=0\n",
    "for i in range (0, len(HMM_predictions)):\n",
    "    if y_pred[i] == \"not moving\":\n",
    "        notwalking_num +=1\n",
    "        \n",
    "        if y_pred[i] == HMM_predictions[i]:\n",
    "            predicted_notwalking +=1\n",
    "            correct_notwalking+=1\n",
    "        else:\n",
    "            predicted_walking+=1\n",
    "    else:\n",
    "        walking_num +=1\n",
    "        if y_pred[i] == HMM_predictions[i]:\n",
    "            correct_walking+=1\n",
    "            predicted_walking+=1\n",
    "        else:\n",
    "            predicted_notwalking+=1\n",
    "    \n",
    "print(\"Walking Count\", walking_num)       \n",
    "print(\"Not Walking Count\", notwalking_num) \n",
    "\n",
    "print(\"HMM Walking Count (Predict)\", predicted_walking)       \n",
    "print(\"HMM Not Walking Count (Predict)\", predicted_notwalking) \n",
    "\n",
    "print(\"HMM Walking Count (Correct)\", correct_walking)       \n",
    "print(\"HMM Not Walking Count (Correct)\", correct_notwalking) \n",
    "print(\"Accuraccy: \", ((correct_walking+correct_notwalking)/(walking_num+notwalking_num))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0b8b8",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e46520",
   "metadata": {},
   "source": [
    "# import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Define the observations\n",
    "observations = np.array([[1, 0, 1, 0, 1], [0, 1, 0, 1, 0], [0, 0, 0, 1, 1]]).reshape(-1, 1)\n",
    "\n",
    "# Define the lengths of the sequences\n",
    "lengths = [5, 5, 5]\n",
    "\n",
    "# Define the CategoricalHMM model\n",
    "model = hmm.CategoricalHMM(n_components=2)\n",
    "\n",
    "# Fit the model to the observations\n",
    "model = model.fit(observations, lengths)\n",
    "\n",
    "# Predict the hidden states\n",
    "hidden_states = model.predict(observations)\n",
    "\n",
    "# Get the probability of the observations\n",
    "prob = model.score(observations, lengths)\n",
    "\n",
    "# Print the hidden states and the probability\n",
    "print(\"Hidden States: \", hidden_states)\n",
    "print(\"Probability of Observations: \", prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17230ad0",
   "metadata": {},
   "source": [
    "#  Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8be5ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"walkingModel.pkl\", \"wb\") as file: pickle.dump(walkingModels, file)\n",
    "#with open(\"notwalkingModel.pkl\", \"wb\") as file: pickle.dump(notwalkingModels, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a0de8",
   "metadata": {},
   "source": [
    "#  Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b70216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"walkingModel.pkl\", \"rb\") as file: walkingmodels = pickle.load(file)\n",
    "with open(\"notwalkingModel.pkl\", \"rb\") as file: notwalkingmodels =pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "298c0a0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 64-65: truncated \\UXXXXXXXX escape (4218438092.py, line 170)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[71], line 170\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 64-65: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "classfication = [\"not moving\", \"moving\"]\n",
    "\n",
    "fileWalkingSet = r\"C:\\Users\\Orozc\\OneDrive\\My Documents\\CPP\\ME 6950\\Test Set\\Walking\"\n",
    "fileNotWalking = r\"C:\\Users\\Orozc\\OneDrive\\My Documents\\CPP\\ME 6950\\Test Set\\Not Walking\"\n",
    "\n",
    "#data sets\n",
    "##walking\n",
    "walking1 = pd.read_csv(fileWalkingSet + \"\\\\Waling 1.txt\", names = columnNames)\n",
    "walking2 = pd.read_csv(fileWalkingSet + \"\\\\Waling 2.txt\", names = columnNames)\n",
    "walking3 = pd.read_csv(fileWalkingSet + \"\\\\Waling 3.txt\", names = columnNames)\n",
    "walking4 = pd.read_csv(fileWalkingSet + \"\\\\Waling 4.txt\", names = columnNames)\n",
    "walking5 = pd.read_csv(fileWalkingSet + \"\\\\Waling 6.txt\", names = columnNames)\n",
    "walking6 = pd.read_csv(fileWalkingSet + \"\\\\Waling7.txt\", names = columnNames)\n",
    "walking7 = pd.read_csv(fileWalkingSet + \"\\\\Waling8.txt\", names = columnNames)\n",
    "walking8 = pd.read_csv(fileWalkingSet + \"\\\\Waling9.txt\", names = columnNames)\n",
    "walking9 = pd.read_csv(fileWalkingSet + \"\\\\Waling10.txt\", names = columnNames)\n",
    "walking10 = pd.read_csv(fileWalkingSet + \"\\\\Waling11.txt\", names = columnNames)\n",
    "\n",
    "\n",
    "##notwalking\n",
    "notwalking1 = pd.read_csv(fileNotWalking + \"\\\\Standing1.txt\", names = columnNames)\n",
    "notwalking2 = pd.read_csv(fileNotWalking + \"\\\\Standing2.txt\", names = columnNames)\n",
    "notwalking3 = pd.read_csv(fileNotWalking + \"\\\\Standing3.txt\", names = columnNames)\n",
    "notwalking4 = pd.read_csv(fileNotWalking + \"\\\\Standing4.txt\", names = columnNames)\n",
    "notwalking5 = pd.read_csv(fileNotWalking + \"\\\\Standing5.txt\", names = columnNames)\n",
    "notwalking6 = pd.read_csv(fileNotWalking + \"\\\\Standing6.txt\", names = columnNames)\n",
    "notwalking7 = pd.read_csv(fileNotWalking + \"\\\\Standing7.txt\", names = columnNames)\n",
    "\n",
    "\n",
    "#dropping depth columns\n",
    "##walking\n",
    "walking1 = walking1.loc[:,~walking1.columns.str.endswith('Depth')]\n",
    "walking2 = walking2.loc[:,~walking2.columns.str.endswith('Depth')]\n",
    "walking3 = walking3.loc[:,~walking3.columns.str.endswith('Depth')]\n",
    "walking4 = walking4.loc[:,~walking4.columns.str.endswith('Depth')]\n",
    "walking5 = walking5.loc[:,~walking5.columns.str.endswith('Depth')]\n",
    "walking6 = walking6.loc[:,~walking6.columns.str.endswith('Depth')]\n",
    "walking7 = walking7.loc[:,~walking7.columns.str.endswith('Depth')]\n",
    "walking8 = walking8.loc[:,~walking8.columns.str.endswith('Depth')]\n",
    "walking9 = walking9.loc[:,~walking9.columns.str.endswith('Depth')]\n",
    "walking10 = walking10.loc[:,~walking10.columns.str.endswith('Depth')]\n",
    "\n",
    "\n",
    "##notwalking\n",
    "notwalking1 = notwalking1.loc[:,~notwalking1.columns.str.endswith('Depth')]\n",
    "notwalking2 = notwalking2.loc[:,~notwalking2.columns.str.endswith('Depth')]\n",
    "notwalking3 = notwalking3.loc[:,~notwalking3.columns.str.endswith('Depth')]\n",
    "notwalking4 = notwalking4.loc[:,~notwalking4.columns.str.endswith('Depth')]\n",
    "notwalking5 = notwalking5.loc[:,~notwalking5.columns.str.endswith('Depth')]\n",
    "notwalking6 = notwalking6.loc[:,~notwalking6.columns.str.endswith('Depth')]\n",
    "notwalking7 = notwalking7.loc[:,~notwalking7.columns.str.endswith('Depth')]\n",
    "\n",
    "\n",
    "#dropping Foot\n",
    "\n",
    "\n",
    "#fixing the columnNames\n",
    "for element in columnNames:\n",
    "    if \"Depth\" in element:\n",
    "        columnNames.remove(element)\n",
    "#Feed the data\n",
    "x_pred = [test1.drop(columns=[\"DateTime\"]).dropna(),test2.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test3.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test4.drop(columns=[\"DateTime\"]).dropna(),test5.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test6.drop(columns=[\"DateTime\"]).dropna(),test7.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test8.drop(columns=[\"DateTime\"]).dropna(),test9.drop(columns=[\"DateTime\"]).dropna(),\n",
    "          test10.drop(columns=[\"DateTime\"]).dropna()]\n",
    "X_pred = []\n",
    "y_pred = []\n",
    "for i in range(0,len(x_pred)):\n",
    "    a=0\n",
    "    frames = 5 #getting the abs average of the frames\n",
    "    #get the closest divisble number of a selected frame\n",
    "    lengths = len(x_pred[i]) - len(x_pred[i])%frames#frames \n",
    "    for j in range(0,lengths-frames,frames): #change in pixel location\n",
    "        a=0\n",
    "\n",
    "        a1 = abs(x_pred[i].iloc[j]-x_pred[i].iloc[j+1])\n",
    "        a2 = abs(x_pred[i].iloc[j+1]-x_pred[i].iloc[j+2])\n",
    "        a3 = abs(x_pred[i].iloc[j+2]-x_pred[i].iloc[j+3])\n",
    "        a4 = abs(x_pred[i].iloc[j+3]-x_pred[i].iloc[j+4])\n",
    "        a5 = abs(x_pred[i].iloc[j+4]-x_pred[i].iloc[j+5])\n",
    "        a = (pd.concat([a1.to_frame().T,a2.to_frame().T,a3.to_frame().T,a4.to_frame().T,a5.to_frame().T])).max()\n",
    "        \n",
    "        X_pred.append(a) #average difference of the five frames\n",
    "       \n",
    "        if i>4:\n",
    "            y_pred.append(classfication[1]) #1 - walking\n",
    "        else:\n",
    "            y_pred.append(classfication[0]) #2 - not walkin\n",
    "            \n",
    "# Predict the hidden states\n",
    "#notwalking_hidden_states = notwalkingModel.predict(X_pred)\n",
    "#notwalking_prob = notwalkingModel.score(X_pred)\n",
    "\n",
    "# Predict the hidden states\n",
    "#walking_hidden_states = walkingModel.predict(X_pred)\n",
    "#walking_prob = walkingModel.score(X_pred)\n",
    "\n",
    "\n",
    "\n",
    "notwalking_prob_next_step_list = []\n",
    "walking_prob_next_step_list = []\n",
    "for j in range(0, modelscount):\n",
    "    #print(i)\n",
    "    walking_prob_next_step = walkingmodels[j].transmat_[walkingmodels[j].predict(X_pred), walkingmodels[j].predict(X_pred)]\n",
    "    notwalking_prob_next_step = notwalkingmodels[j].transmat_[notwalkingmodels[j].predict(X_pred), notwalkingmodels[j].predict(X_pred)]\n",
    "    walking_prob_next_step_list.append(walking_prob_next_step)\n",
    "    notwalking_prob_next_step_list.append(notwalking_prob_next_step)\n",
    "#print(max(walkingprob_list),max(notwalkingprob_list))\n",
    "\n",
    "\n",
    "HMM_predictions = []\n",
    "walkingprob_list = []\n",
    "notwalkingprob_list = []\n",
    "walking_step_probablity = []\n",
    "notwalking_step_probablity = []    \n",
    "for i in range(0, len(X_pred)):\n",
    "    a=[]\n",
    "    b=[]\n",
    "    for j in range(0, modelscount):\n",
    "        a.append(notwalking_prob_next_step_list[j][i])\n",
    "        b.append(walking_prob_next_step_list[j][i])\n",
    "    notwalking_step_probablity.append(max(a))\n",
    "    walking_step_probablity.append(max(b))\n",
    "    notwalkingprob=(max(a))\n",
    "    walkingprob=(max(b))\n",
    "    #print(notwalkingprob,walkingprob)\n",
    "    if walkingprob > notwalkingprob:\n",
    "        HMM_predictions.append(classfication[1])#1 - walking\n",
    "    else:\n",
    "        HMM_predictions.append(classfication[0])#0 - ot walking\n",
    "        \n",
    "        \n",
    "# compare HMM predictions vs actual labels\n",
    "correct_walking = 0 #correct \n",
    "correct_notwalking = 0 #correct\n",
    "walking_num = 0 #track of overall count\n",
    "notwalking_num = 0  #tack overall count\n",
    "predicted_walking = 0\n",
    "predicted_notwalking=0\n",
    "\n",
    "for i in range (0, len(HMM_predictions)):\n",
    "    if y_pred[i] == \"not moving\":\n",
    "        notwalking_num +=1\n",
    "        \n",
    "        if y_pred[i] == HMM_predictions[i]:\n",
    "            predicted_notwalking +=1\n",
    "            correct_notwalking+=1\n",
    "        else:\n",
    "            predicted_walking+=1\n",
    "    else:\n",
    "        walking_num +=1\n",
    "        if y_pred[i] == HMM_predictions[i]:\n",
    "            correct_walking+=1\n",
    "            predicted_walking+=1\n",
    "        else:\n",
    "            predicted_notwalking+=1\n",
    "    \n",
    "print(\"Walking Count\", walking_num)       \n",
    "print(\"Not Walking Count\", notwalking_num) \n",
    "\n",
    "print(\"HMM Walking Count (Predict)\", predicted_walking)       \n",
    "print(\"HMM Not Walking Count (Predict)\", predicted_notwalking) \n",
    "\n",
    "print(\"HMM Walking Count (Correct)\", correct_walking)       \n",
    "print(\"HMM Not Walking Count (Correct)\", correct_notwalking) \n",
    "print(\"Accuraccy: \", ((correct_walking+correct_notwalking)/(walking_num+notwalking_num))*100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f009283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
